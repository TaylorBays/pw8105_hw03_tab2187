---
title: "Homework 03"
output: html_document
date: "2022-10-15"
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 0
Created a R project to organize my work, a R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures to my files. Successfully established a git repository to upload commit history. 

##Problem 1
```{r}
# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")
```

Had to download Rtools42 for windows to access the p8105 datasets (https://cran.r-project.org/bin/windows/Rtools/rtools42/rtools.html). Hopefully this is legit and I did not download a virus. Since that is completed I can move on to problem 1. 

```{r}
library(p8105.datasets)
data("instacart")
View(instacart)
```

#### Read in the data

```{r}
data("instacart")

instacart = 
  instacart %>% 
  as_tibble(instacart)
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row resprenting a single product from an instacart order. Variables include identifiers for user, order, and product; the order in which each product was added to the cart. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. In total, there are `r instacart %>% select(product_id) %>% distinct %>% count` products found in `r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders from `r instacart %>% select(user_id) %>% distinct %>% count` distinct users.

Below is a table summarizing the number of items ordered from aisle. In total, there are 134 aisles, with fresh vegetables and fresh fruits holding the most items ordered by far.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Next is a plot that shows the number of items ordered in each aisle. Here, aisles are ordered by ascending number of items.

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

Our next table shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and includes the number of times each item is ordered in your table.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

Finally is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. This table has been formatted in an untidy manner for human readers. Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

##Problem 2
Load, tidy, and otherwise wrangle the data. Your final dataset should include all originally observed variables and values; have useful variable names; include a weekday vs weekend variable; and encode data with reasonable variable classes. Describe the resulting dataset (e.g. what variables exist, how many observations, etc).

Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each day, and create a table showing these totals. Are any trends apparent?

```{r}
accel=
  read.csv("accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_num",
    values_to = "activity") %>%
  mutate(
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
    weekday_vs_weekend =
      if_else(day %in% c("Saturday", "Sunday"), "Weekend", "Weekday")) %>% 
  group_by(week, day) %>% 
  summarise(total_activity = sum(activity)) %>% 
  pivot_wider(
    names_from = "day",
    values_from = "total_activity"
  )
view(accel)
```

-->With the table created from this code chunk we see that the person had higher activity levels on Friday's. His second and third highest ranking days were Wednesday and Thursday. The patient was also the most active during Week 2. His second and third highest ranking weeks were Week 3 and 5. The patient has odd activity data on Saturday's for Week 3 and Week 4. We can hypothesize that the patient took off the accelerometer to charge it around the same time each Saturday but did not take off the monitor for the other Saturday's.


```{r}
accel=
  read.csv("accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_num",
    values_to = "activity") %>%
  mutate(
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
    weekday_vs_weekend =
      if_else(day %in% c("Saturday", "Sunday"), "Weekend", "Weekday")) %>% 
  group_by(week, day) %>% 
  summarise(total_activity = sum(activity)) %>% 
  pivot_wider(
    names_from = "day",
    values_from = "total_activity"
  )
view(accel)
```



Accelerometer data allows the inspection activity over the course of the day. Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. Describe in words any patterns or conclusions you can make based on this graph.

accel %>% 
  ggplot(aes(x = total_activity, y = tmax, color = name)) +
  geom_point(aes(size = .5), alpha =.3)  +
  geom_smooth(se = FALSE) + 
  facet_grid(. ~ name)+
  theme(axis.text.x = element_text(angle =90, vjust = 0.5, hjust=1))

```{r}

```


##Problem 3
```{r}
library(p8105.datasets)
data("ny_noaa")
View(ny_noaa)
```

```{r}
data("ny_noaa")

ny_noaa = 
  ny_noaa %>% 
  as_tibble(ny_noaa)
```
This dataset contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns, with each row representing a data from one of the 100,000 weather stations. Variables include identifiers for weather station id, date of observation, precipitation, snowfall, snow depth, maximum temperature and minimum temperature. Precipitation, snowfall, and snow depth are measured in millimeters, while temperature is measured using Celsius to the tenths of a degree.

Below is a table summarizing the number of different weather stations that have collected data. In total, there are 747 weather stations represented, with US1NYCN0011, US1NYCES0005, and USNYSF0030 with the least amount of data entries (days of weather information) all three having 30 days of entries.

```{r}
ny_noaa %>% 
  count(id) %>% 
  arrange(desc(n))
```

Do some data cleaning. Create separate variables for year, month, and day. 

```{r}
 ny_noaa_tidy=
  ny_noaa %>% 
  janitor::clean_names() %>% 
   separate(date, into = c("year", "month", "day")) %>% 
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>% 
  mutate(month = month.name[as.integer(month)])
View(ny_noaa_tidy)
```

Ensure observations for temperature are in degrees Celsuis not "tenths of degrees C". Ensure precipitation and snowfall are given in reasonable units. Since snowfall is already in mm it does not need to be changed but precipitation is in tenths of a mm so that needs to be correct in a similar fashion to the minimum and maximum temperature.

```{r}
ny_noaa_tidy =  
  ny_noaa %>% 
  sample_n(2000) %>% 
  janitor::clean_names() %>% 
   separate(date, into = c("year", "month", "day")) %>% 
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>% 
  mutate(month = month.name[as.integer(month)]) %>% 
  mutate(tmin= as.numeric(tmin)) %>% 
  mutate(tmin = as.numeric(tmin / 10)) %>%
  mutate(tmax= as.numeric(tmax)) %>% 
  mutate(tmax = as.numeric(tmax / 10)) %>%
  mutate(prcp= as.numeric(prcp)) %>% 
  mutate(prcp = as.numeric(prcp / 10)) %>% 
 select(id, month, year, day, prcp, snow, snwd, tmax, tmin)
```


For snowfall what are the most commonly observed values. Why? 
We see that`0` was observed 2008508 times,  `25` was observed 31022 times, and `13` was observed 23095 times. There was no data for data entries 381221 times. I would assume `0` was measured so many times because on those days no snow fell, therefore the measured snowfall would be 0.
```{r}
ny_noaa_tidy %>% 
  count(snow) %>% 
arrange(desc(n))
```


```{r}
ny_noaa_tidy%>% 
mean(tmax, na.rm = TRUE)
```

Make a two-panel plot showing the average max temperature in January and in July in each station across years. Is there any observable / interpretable structure? Any outliers?

```{r}
ny_noaa_tidy %>% 
  group_by(month, year, id) %>% 
  filter(
    month %in% c("January", "July")) %>%
  summarize(
    tmax_mean = mean(tmax, na.rm = TRUE)
  ) %>% 
  ggplot(aes(x = year, y = tmax_mean, color = id)) +
  geom_density(alpha =0.5) +
  facet_grid(.~month)

theme(axis.text.x = element_blank(), legend.position = "none")
```

Make a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option); and (ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.

```{r}

```

